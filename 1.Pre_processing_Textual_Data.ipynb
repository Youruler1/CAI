{"cells":[{"cell_type":"markdown","metadata":{"id":"CqsalmBmmvxZ"},"source":["# Converting Corpus to Features\n","\n","\n","In order to convert corpus to feature matrix, following steps are used:\n","1. Loading your own corpus\n","2. Pre-processing corpus: Normalization, Tokenization, Stop-word Removal, Stemming\n","3. Converting pre-processed corpus to feature matrix (TDM/DTM or TTM)"]},{"cell_type":"markdown","metadata":{"id":"k6fDkvQBmvxo"},"source":["# Loading your own corpus\n","User defined corpus can be imported in Python using two methods:\n","1. Using nltk.corpus PlainTextCorpusReader or CategorizedCorpusReader\n","2. Using file method of Python"]},{"cell_type":"markdown","metadata":{"id":"BBduVJIcmvxq"},"source":["# CorpusReader\n","\n","![20.png](attachment:20.png)\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"3r_Fr_H2-jQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BX6uP7tY-lb0","outputId":"23284a2c-5931-492e-8b34-7fc645621d69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzlDV9pMmvxs"},"outputs":[],"source":["from nltk.corpus import PlaintextCorpusReader\n","#path='C:/Users/Desktop/dataset/'\n","path='/content/drive/MyDrive/CONVAI/DATA/'\n","\n","\n","dataset=PlaintextCorpusReader(path,'.*')\n"]},{"cell_type":"code","source":["dataset.fileids()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmPvPfrXCE53","outputId":"d832f2cd-8c95-4ba8-f860-0845506bcb0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1.txt', '2.txt', '3.txt', '4.txt']"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["dataset.raw(fileids='1.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"39OyURnbC6zb","outputId":"f07f4efd-0fca-4295-c372-e6e9677a56c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Data Science is an important field of science .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrJoByRvmvxx","outputId":"3314b18a-e908-4295-89ce-bedcf19ec5aa","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Data Science is an important field of science .',\n"," 'This is an important data science course .',\n"," 'The cars are driven on the roads .',\n"," 'The trucks are driven on the highways .']"]},"metadata":{},"execution_count":16}],"source":["#Converting the dataset to a list (where each string represents a seperate document)\n","corpus=[]\n","for i  in dataset.fileids():\n","    corpus.append(dataset.raw(fileids=i))\n","corpus"]},{"cell_type":"markdown","metadata":{"id":"eRDTlahYmvx1"},"source":["# Loading Corpus Using File Method of Python\n","\n","Using files:  \n","File_object=open(r\"File_Name\",\"Access_Mode\")\n","\n","Access Modes :\n","1. Read Only (‘r’)\n","2. Read and Write (‘r+’)\n","3. Write Only (‘w’)\n","4. Write and Read (‘w+’)\n","5. Append Only (‘a’)\n","6. Append and Read (‘a+’)"]},{"cell_type":"code","source":["import os\n","filenames=os.listdir(path)\n","filenames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MrhvpHfEql6","outputId":"a5f5daee-ef8e-4e71-8b91-d3585857d1c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1.txt', '2.txt', '3.txt', '4.txt']"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"BBPd58wcFlMx","outputId":"d4299364-b839-417b-c33f-7a31500d3ab5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/CONVAI/DATA/'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QiyVEtQMmvx4","outputId":"2ffee9d8-0769-4b11-feba-ae259119ba4f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Data Science is an important field of science .',\n"," 'This is an important data science course .',\n"," 'The cars are driven on the roads .',\n"," 'The trucks are driven on the highways .']"]},"metadata":{},"execution_count":24}],"source":["\n","filenames=os.listdir(path)\n","corpus=[]\n","for i  in range(len(filenames)):\n","    f=open(path+filenames[i],'r')\n","    corpus.append(f.read())\n","    f.close()\n","corpus"]},{"cell_type":"markdown","metadata":{"id":"Qs91uWBfmvx6"},"source":["# Pre-processing: Step 1: Normalization\n","\n","Normalization in text includes following steps:\n","1. Converting the text into same case (lower, upper, or proper case)\n","2. Removing numbers, special symbols, urls from text.\n"]},{"cell_type":"markdown","source":["text = \"Hello World\"\n","\n","lower_text = text.lower()\n","\n","text = \"Hello World\"\n","\n","split_text = text.split()\n","\n","words = [\"This\", \"is\", \"a\", \"sentence\"]\n","\n","sentence = ' '.join(words)\n"],"metadata":{"id":"iCjgy4gzGdep"}},{"cell_type":"code","source":["corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieLqwcexGsht","outputId":"dc37e13c-027d-4447-bd97-5a6daee8cac7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Data Science is an important field of science .',\n"," 'This is an important data science course .',\n"," 'The cars are driven on the roads .',\n"," 'The trucks are driven on the highways .']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["for i in corpus:\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHWeP0ZsIQoU","outputId":"f56c003e-16fc-4424-9e9f-451e26c329f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Science is an important field of science .\n","This is an important data science course .\n","The cars are driven on the roads .\n","The trucks are driven on the highways .\n"]}]},{"cell_type":"code","source":["lower=[]\n","for i in corpus:\n","  s=\"\"\n","  s=' '.join(x.lower() for x in i.split())\n","  #print(s)\n","  lower.append(s)\n","lower\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jiv71IUIgrJ","outputId":"d07a51c5-3b19-4f00-bda5-659b2a88c9eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data science is an important field of science .',\n"," 'this is an important data science course .',\n"," 'the cars are driven on the roads .',\n"," 'the trucks are driven on the highways .']"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAGjTdcqmvx8","outputId":"9a823031-8952-4332-d22b-921e85110045","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data science is an important field of science .',\n"," 'this is an important data science course .',\n"," 'the cars are driven on the roads .',\n"," 'the trucks are driven on the highways .']"]},"metadata":{},"execution_count":25}],"source":["#Converting text to lower case using .lower() method of NLTK\n","lower=[]\n","for i in corpus:\n","    lower.append(' '.join([word.lower() for word in i.split()]))\n","lower"]},{"cell_type":"markdown","source":["Remove special symbols, punctuation, and URLs\n","\n","cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n","\n","text = re.sub(r'http\\S+|www\\S+', '', text) text=re.sub(r'\\d+','',text)\n","\n","^ - negate\n","\n","\\w+ matches sequences of one or more word characters (letters, digits, and underscores).\n","\n","+ symbol one or more occurrences\n","\n","\\d+ matches sequences of one or more digits. It finds all sequences of digits in the text.\n","\n","\\s: Matches any whitespace character (space, tab, newline, etc.).\n","\n","\\S: Matches any non-whitespace character (letters, digits, punctuation, etc.).\n","\n","\\W: This matches any character that is not a word character. A word character is defined as a letter (a-z, A-Z), a digit (0-9), or an underscore (_)."],"metadata":{"id":"MsE67b7UqWI5"}},{"cell_type":"code","source":["import re\n","def clean_text(text):\n","    # Remove URLs\n","    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","        # Remove numbers\n","    text = re.sub(r'\\d+', '', text)\n","        # Remove special characters (except for alphabets and spaces)\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","        # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","# Clean each document in the corpus\n","cleaned_corpus = [clean_text(doc) for doc in corpus]\n","\n","print(cleaned_corpus)\n"],"metadata":{"id":"zC2xFsXrPT8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBZWURaemvx-","outputId":"d01a2925-863c-4bc2-b965-7593c940c7b7","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data science is an important field of science',\n"," 'this is an important data science course',\n"," 'the cars are driven on the roads',\n"," 'the trucks are driven on the highways']"]},"metadata":{},"execution_count":39}],"source":["# Removing numbers, special symbols, urls using .isalpha() method of NLTK\n","alpha=[]\n","for i in lower:\n","    alpha.append(' '.join([word for word in i.split() if word.isalpha()]))\n","alpha"]},{"cell_type":"markdown","metadata":{"id":"faG45XiQmvyA"},"source":["`# Pre-processing Step 2: Tokenization\n","\n","Tokenization involves converting each document as list of words. It can be done in two ways:\n","1. .split() method of list\n","2. word_tokenize method of nltk.tokenize"]},{"cell_type":"code","source":["tokenize=[]\n","for i in alpha:\n","  s=i.split()\n","  tokenize.append(s)\n","tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtm1_zQlQXu0","outputId":"9c8fb64f-11c0-4adb-f222-492ebf84c579"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['data', 'science', 'is', 'an', 'important', 'field', 'of', 'science'],\n"," ['this', 'is', 'an', 'important', 'data', 'science', 'course'],\n"," ['the', 'cars', 'are', 'driven', 'on', 'the', 'roads'],\n"," ['the', 'trucks', 'are', 'driven', 'on', 'the', 'highways']]"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOE0j_T-mvyA","outputId":"6fe71756-d6d5-425a-f321-1b4950ae624a"},"outputs":[{"data":{"text/plain":["[['data', 'science', 'is', 'an', 'important', 'field', 'of', 'science'],\n"," ['this', 'is', 'an', 'important', 'data', 'science', 'course'],\n"," ['the', 'cars', 'are', 'driven', 'on', 'the', 'roads'],\n"," ['the', 'trucks', 'are', 'driven', 'on', 'the', 'highways']]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["#Tokenization using .split()\n","tokenize=[]\n","for i in alpha:\n","    tokenize.append([word for word in i.split()])\n","tokenize"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3lq46AdRgva","outputId":"d6b8da54-401e-48e1-ceb1-c62b3e39ffc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-FpWSH6mvyC","outputId":"cc10d5cd-3ee5-404a-bb53-0ca2dd4389ce","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['data', 'science', 'is', 'an', 'important', 'field', 'of', 'science'],\n"," ['this', 'is', 'an', 'important', 'data', 'science', 'course'],\n"," ['the', 'cars', 'are', 'driven', 'on', 'the', 'roads'],\n"," ['the', 'trucks', 'are', 'driven', 'on', 'the', 'highways']]"]},"metadata":{},"execution_count":47}],"source":["#Tokenization using word_tokenize\n","tokenize=[]\n","from nltk.tokenize import word_tokenize\n","for i in alpha:\n","    tokenize.append(word_tokenize(i))\n","tokenize"]},{"cell_type":"markdown","metadata":{"id":"FmA4VllemvyD"},"source":["# Pre-processing Step 3: Stop-word Removal\n","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that does not have any linguistic importance in NLP applications\n","\n","NLTK(Natural Language Toolkit) in python has a list of stopwords stored in stopwords corpus in 16 different languages.\n","\n","The name of fields is the name of language."]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"762Z-Nl3SucW","outputId":"1df9af6b-8dfb-4f00-d4a5-ab6b08b12932"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdWbtzxymvyE","outputId":"fe59fc8d-17a2-4783-fe28-a7b5a100b311","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['data', 'science', 'important', 'field', 'science'],\n"," ['important', 'data', 'science', 'course'],\n"," ['cars', 'driven', 'roads'],\n"," ['trucks', 'driven', 'highways']]"]},"metadata":{},"execution_count":50}],"source":["from nltk.corpus import *\n","stopword=stopwords.words('english') #stopword will contain list of all stopwords of english language\n","no_stop=[]\n","for i in tokenize:\n","    no_stop.append([word for word in i if word not in stopword])\n","no_stop"]},{"cell_type":"code","source":["for i in tokenize:\n","  print(i)\n","  for word in i:\n","    if word not in stopword:\n","      print(word)\n","\n","#     no_stop.append([word for word in i if word not in stopword])\n","# no_stop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBWueXWSV4rj","outputId":"097c5e0d-108b-4142-efff-07bd09b22a85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['data', 'science', 'is', 'an', 'important', 'field', 'of', 'science']\n","data\n","science\n","important\n","field\n","science\n","['this', 'is', 'an', 'important', 'data', 'science', 'course']\n","important\n","data\n","science\n","course\n","['the', 'cars', 'are', 'driven', 'on', 'the', 'roads']\n","cars\n","driven\n","roads\n","['the', 'trucks', 'are', 'driven', 'on', 'the', 'highways']\n","trucks\n","driven\n","highways\n"]}]},{"cell_type":"code","source":["for i in tokenize:\n","  l=[]\n","  for word in i:\n","    if word not in stopword:\n","      l.append(word)\n","no_stop.append(l)\n","no_stop\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6ShF4mSWRel","outputId":"77f7e008-204d-4442-ff13-42cefe1c7ba5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['data', 'science', 'important', 'field', 'science'],\n"," ['important', 'data', 'science', 'course'],\n"," ['cars', 'driven', 'roads'],\n"," ['trucks', 'driven', 'highways'],\n"," ['trucks', 'driven', 'highways'],\n"," ['trucks', 'driven', 'highways']]"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["no_stop=[]\n","for i in tokenize:\n","  no_stop.append([word for word in i if word not in stopword])\n","no_stop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERQKi9WpWt3c","outputId":"b0610f81-e87c-49b6-b22c-950df896fb17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['data', 'science', 'important', 'field', 'science'],\n"," ['important', 'data', 'science', 'course'],\n"," ['cars', 'driven', 'roads'],\n"," ['trucks', 'driven', 'highways']]"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"jtctY6y6mvyF"},"source":["# Pre-processing Step 4: Stemming\n","\n","Stemming is a process that maps variant word forms to their base forms (play, plays, playing, played )\n","\n","nltk.stem has number of stemming algorithms named as \"PorterStemmer\", \"LancasterStemmer\", etc. These algorithms accepts the list of tokenized word and stems it into root word.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLx8-25cmvyG","outputId":"951592d0-2f7b-4d27-d488-3324e708af4c","colab":{"base_uri":"https://localhost:8080/","height":36}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'unhappi'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":68}],"source":["#Stemming Example\n","from nltk.stem import PorterStemmer #Importing porter stemmer class\n","ps=PorterStemmer() #Creating an object of PorterStemmer Class\n","ps.stem('unhappy') #stemming a word using .stem method"]},{"cell_type":"code","source":[],"metadata":{"id":"tiDnKGguXX3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bn372sAUmvyH","outputId":"cdb33689-6002-4c4a-d8e9-e524daf8fe5c"},"outputs":[{"data":{"text/plain":["['data scienc import field scienc',\n"," 'import data scienc cours',\n"," 'car driven road',\n"," 'truck driven highway']"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["#Stemming the corpus\n","final=[] #will contain final pre-processed documents\n","from nltk.stem import PorterStemmer\n","ps=PorterStemmer()\n","for i in no_stop:\n","    final.append(' '.join([ps.stem(word) for word in i]))\n","final"]},{"cell_type":"code","source":["from nltk.stem import LancasterStemmer\n","\n","# Initialize the Lancaster Stemmer\n","ls = LancasterStemmer()\n","final = []\n","# Stemming the corpus\n","for i in no_stop:\n","   final.append(' '.join([ls.stem(word) for word in i]))\n","\n","print(final)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIWazu7kZckv","outputId":"9e86a4e5-97af-4d8b-e08b-3d360516c682"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['dat sci import field sci', 'import dat sci cours', 'car driv road', 'truck driv highway']\n"]}]},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2Yn9lpCXkux","outputId":"f556eff7-5036-484a-b22f-634edcd2ad84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","words = ['running', 'flies', 'better', 'cats']\n","\n","# Lemmatize each word\n","lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","print(lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lVlBKEmXnWW","outputId":"c870469d-4608-4ce2-fd0b-fde53b14c8b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['running', 'fly', 'better', 'cat']\n"]}]},{"cell_type":"code","source":["words_with_pos = [('running', 'v'), ('flies', 'n'), ('better', 'a'), ('cats', 'n')]\n","# Lemmatize each word with its POS tag\n","lemmatized_words_with_pos = [lemmatizer.lemmatize(word, pos) for word, pos in words_with_pos]\n","print(lemmatized_words_with_pos)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yAj84MxyX2cR","outputId":"4f56ff49-3d38-4f76-d457-a141013942e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['run', 'fly', 'good', 'cat']\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer\n","\n","# Initialize lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# Define a function to convert POS tags\n","def get_wordnet_pos(treebank_tag):\n","    if treebank_tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif treebank_tag.startswith('V'):\n","        return wordnet.VERB\n","    elif treebank_tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif treebank_tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return wordnet.NOUN\n","\n","# Define words to be lemmatized\n","words = ['running', 'flies', 'better', 'cats']\n","\n","# POS tagging\n","pos_tagged_words = nltk.pos_tag(words)\n","\n","# Lemmatize each word with its POS tag\n","lemmatized_words_with_pos = [\n","    lemmatizer.lemmatize(word, get_wordnet_pos(pos_tag))\n","    for word, pos_tag in pos_tagged_words\n","]\n","\n","print(lemmatized_words_with_pos)\n"],"metadata":{"id":"CpTakR1ZnuwJ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}